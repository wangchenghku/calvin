The essence of Calvin lies in separating the system into three separate layers of processing:

- The sequencing layer (or "sequencer") intercepts transactional inputs and places them into a global transactional input sequence - this sequence will be the order of transactions to which all replicas will ensure serial equivalence during their execution.

- The scheduling layer (or "scheduler") orchestrates transaction execution using a deterministic locking scheme to guarantee equivalence to the serial order specified by the sequencing layer while allowing transactions to be executed concurrently by a pool of transaction execution threads.

- The storage layer handles all physical data layout.

Synchronous and asynchronous replication
Calvin currently supports two modes for replicating transactional input: asynchronous replication and Paxos-based synchronous replication. In both modes, nodes are organized into replication groups, each of which contains all replicas of a particular partition. For example, partition 1 in replica A and partition 1 in replica B would together form one replication group.
In asynchronous replication mode, one replica is designated as a master replica, and all transaction requests are forwarded immediately to sequencer located at nodes of this replica. After compiling each batch, the sequencer component on each master node forwards the batch to all other (slave) sequencers in its replication group.

Calvin also supports Paxos-based synchronous replication of transactional inputs. In this mode, all sequencers within a replication group use Paxos to agree on a combined batch of transaction requests for each epoch. Calvin's current implementation uses ZooKeeper, a highly reliable distributed coordination service often used by distributed database systems for heartbeats, configuration synchronization and naming.

In its current implementation, Calvin handles hardware failures by recovering the crashed machine from its most recent complete snapshot and then replaying all more recent transactions. Since other nodes within the same replica may depend on remote reads from the afflicted machine, however, throughput in the rest of the replica is opt to slow or halt until recovery is complete.

Prerequisites
  - GNU/Linux distro >= 2.6.37.6
  - G++ >= 4.5.1
  - Satisfy all dependencies of the following external libraries
      -# GoogleTest      - Google's Unit Testing Framework
          - Object Linking: ext/googletest/lib/.libs
          - Header Include: ext/googletest/include
      -# ProtocolBuffers - Google's Framework for Serializable PODS
          - Object Linking: ext/protobuf/src/.libs
          - Header Include: ext/protobuf/src
      -# ZeroMQ          - Efficient Message Passing System
          - Object Linking: ext/zeromq/src/.libs
          - Header Include: ext/zeromq/include
      -# Zookeeper       - Apache Implementation of Paxos protocol
          - Object Linking: ext/zookeeper/.libs
          - Header Include: ext/zookeeper/include ext/zookeeper/generated

The source folder is comprised of several scripts and directories:
     - README            - This file
     - INSTALL           - A detailed (yet slightly outdated) list of installation instructions
     - ./install-ext     - A script to install all external libraries linked to this project
     - deploy-run.conf   - Include the machines which Calvin run on
     - ext/              - Contains several external libraries used in Calvin that must be compiled and linked to source
     - src_calvin/       - The basic Calvin codebase
     - src_calvin_3_partitions/    - The Calvin codebase that each distributed transaction spans 3 partitions
(TODO: We plan to combine some folders related to src_calvin_* into one codebase, and so as to src_traditional_*)


Installation
  In order to compile external libraries associated w/Calvin, please run: 
    $ ./install-ext
  To compile the source, please run:
    $ mv src_*** src
    $ cd src
    $ make -j
  Two directories will be created: bin/, obj/ and logs/.
   - obj/      - Where all the .o and some .d (dependency files) are sent to
   - bin/      - Where all the binary and some .d (dependency files) are written

  In order to run an executable (including an individual test) simply invoke the
  appropriate binary file from the command line.  For example, if you wanted to
  run calvin_ctl (the executable for launching Calvin), you would invoke from
  the root directory:
    $ bin/deployment/cluster -c deploy-run.conf -p src/deployment/portfile -d bin/deployment/db m 0
    # bin/deployment/cluster -c config-file -p port-file -d db-exec

  deploy-run.conf:
  # Node<id>=<replica>:<partition>:<cores>:<host>:<port>
  node0=0:0:8:128.36.232.18:54564
  node1=0:1:8:128.36.232.12:54564
  node2=0:2:8:128.36.232.15:54564
  node3=0:3:8:128.36.232.20:54564
  node4=0:4:8:128.36.232.19:54564
  ...

   If you only run it on one machine, just run the command from the root directory:
   $ bin/deployment/db 0 m 0
   # bin/deployment/db <node-id> <m[icro]|t[pcc]> <percent_mp>

  Note that: Since all experiments we did before were ran on 8 cores machines, current codebase only can be running on 8 cores machines, we will make it more general in the future. If you want to run it on multiple machines, you should make sure each machine has the same user name and each machine is able to ssh the other machines without password, like "ssh 128.26.232.18". Also you need to make sure each machine has the exactly same code, and you should build the same code on each machine.

  And there are some import parameters you need to edit :
   - src/sequencer/sequencer.h: #define MAX_BATCH_SIZE *** : Set batch size per 10 ms epoch , set it a little bigger than the actually throughput(200 means every second the sequencer creates 20K transactions)     

  You should make sure that your LD_LIBRARY_PATH includes the object files noted in the dependencies above. And you need to edit deploy-run.conf to include the machines which Calvin run on(The port should be same with the port in the src/deployment/portfile).


